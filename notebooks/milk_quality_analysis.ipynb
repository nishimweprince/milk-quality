{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33378c25",
   "metadata": {},
   "source": [
    "# Milk Quality Analysis and Machine Learning Pipeline\n",
    "\n",
    "This notebook demonstrates the complete pipeline for milk quality analysis, including data generation with realistic variations, exploratory data analysis, model training and evaluation with multiple algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb82925",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('viridis')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f860a031",
   "metadata": {},
   "source": [
    "## 1. Data Generation with Realistic Variations\n",
    "\n",
    "Generate synthetic milk quality data with sufficient randomness to ensure realistic model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967c8bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_training_data(n_samples=50000):\n",
    "    '''Generate synthetic training data with realistic variations'''\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    ph_values = np.random.uniform(5.5, 7.5, n_samples)  # Expanded pH range\n",
    "    turbidity = np.random.uniform(0.5, 30.0, n_samples)  # Expanded turbidity range\n",
    "    ec_values = np.random.uniform(3.5, 7.0, n_samples)   # Expanded EC range\n",
    "    protein_content = np.random.uniform(1.5, 4.0, n_samples)  # Expanded protein range\n",
    "    \n",
    "    scc_distribution = np.random.choice(['low', 'medium', 'high', 'very_high', 'extreme'], \n",
    "                                      size=n_samples, \n",
    "                                      p=[0.4, 0.3, 0.15, 0.1, 0.05])  # Adjusted probabilities\n",
    "    \n",
    "    scc_values = np.zeros(n_samples)\n",
    "    for i, dist in enumerate(scc_distribution):\n",
    "        if dist == 'low':\n",
    "            scc_values[i] = np.random.uniform(10000, 200000)\n",
    "        elif dist == 'medium':\n",
    "            scc_values[i] = np.random.uniform(200001, 400000)\n",
    "        elif dist == 'high':\n",
    "            scc_values[i] = np.random.uniform(400001, 1200000)\n",
    "        elif dist == 'very_high':\n",
    "            scc_values[i] = np.random.uniform(1200001, 5000000)\n",
    "        else:  # extreme\n",
    "            scc_values[i] = np.random.uniform(5000001, 10000000)\n",
    "    \n",
    "    action_mapping = {\n",
    "        'Negative': 'Safe to use',\n",
    "        'Trace': 'Monitor',\n",
    "        'Weak_Positive': 'Check the cow',\n",
    "        'Distinct_Positive': 'Veterinary care',\n",
    "        'Definite_Positive': 'Reject the milk'\n",
    "    }\n",
    "    \n",
    "    quality_categories = []\n",
    "    actions = []\n",
    "    \n",
    "    for i in range(n_samples):\n",
    "        scc = scc_values[i]\n",
    "        ph = ph_values[i]\n",
    "        turb = turbidity[i]\n",
    "        ec = ec_values[i]\n",
    "        \n",
    "        if np.random.random() < 0.2:\n",
    "            label = np.random.choice(['Negative', 'Trace', 'Weak_Positive', 'Distinct_Positive', 'Definite_Positive'])\n",
    "        else:\n",
    "            if scc <= 200_000:\n",
    "                if (ph < 6.0 or ph > 7.0 or turb > 5.0 or ec > 5.5) and np.random.random() < 0.3:\n",
    "                    label = 'Trace'\n",
    "                else:\n",
    "                    label = 'Negative'\n",
    "            elif scc <= 400_000:\n",
    "                rand = np.random.random()\n",
    "                if rand < 0.3:\n",
    "                    label = 'Negative'\n",
    "                elif rand < 0.6:\n",
    "                    label = 'Weak_Positive'\n",
    "                else:\n",
    "                    label = 'Trace'\n",
    "            elif scc <= 1_200_000:\n",
    "                rand = np.random.random()\n",
    "                if rand < 0.3:\n",
    "                    label = 'Trace'\n",
    "                elif rand < 0.6:\n",
    "                    label = 'Distinct_Positive'\n",
    "                else:\n",
    "                    label = 'Weak_Positive'\n",
    "            elif scc <= 5_000_000:\n",
    "                rand = np.random.random()\n",
    "                if rand < 0.3:\n",
    "                    label = 'Weak_Positive'\n",
    "                elif rand < 0.6:\n",
    "                    label = 'Definite_Positive'\n",
    "                else:\n",
    "                    label = 'Distinct_Positive'\n",
    "            else:\n",
    "                if np.random.random() < 0.3:\n",
    "                    label = 'Distinct_Positive'\n",
    "                else:\n",
    "                    label = 'Definite_Positive'\n",
    "        \n",
    "        quality_categories.append(label)\n",
    "        actions.append(action_mapping[label])\n",
    "    \n",
    "    df = pd.DataFrame({\n",
    "        'pH': ph_values,\n",
    "        'Turbidity': turbidity,\n",
    "        'EC': ec_values,\n",
    "        'Protein': protein_content,\n",
    "        'SCC': scc_values,\n",
    "        'MilkQuality': quality_categories,\n",
    "        'Action': actions\n",
    "    })\n",
    "    \n",
    "    os.makedirs('data', exist_ok=True)\n",
    "    df.to_csv('data/milk_quality_training_data.csv', index=False)\n",
    "    print(f\"Generated {n_samples} samples and saved to data/milk_quality_training_data.csv\")\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77611e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the data\n",
    "df = generate_training_data()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd05de9",
   "metadata": {},
   "source": [
    "## 2. Exploratory Data Analysis\n",
    "\n",
    "Analyze the distribution of milk quality categories and relationships between features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53981ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display quality distribution\n",
    "quality_counts = df['MilkQuality'].value_counts()\n",
    "print(\"Milk Quality Distribution:\")\n",
    "print(quality_counts)\n",
    "print(\"\\nPercentage Distribution:\")\n",
    "print(quality_counts / len(df) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb752dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot quality distribution\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.countplot(data=df, x='MilkQuality', order=df['MilkQuality'].value_counts().index, palette='viridis')\n",
    "plt.title('Milk Quality Distribution', fontsize=14)\n",
    "plt.ylabel('Count', fontsize=12)\n",
    "plt.xlabel('Quality Category', fontsize=12)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8588c701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample data for visualization (using a smaller subset for better visualization)\n",
    "df_sample = df.sample(1000, random_state=42)\n",
    "\n",
    "sns.pairplot(df_sample, hue='MilkQuality', vars=['pH', 'Turbidity', 'EC', 'Protein', 'SCC'])\n",
    "plt.suptitle('Pairplot of Sampled Milk Data', y=1.02, fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ebc745",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create boxplots to visualize feature distributions by quality category\n",
    "features = ['pH', 'Turbidity', 'EC', 'Protein', 'SCC']\n",
    "\n",
    "fig, axes = plt.subplots(len(features), 1, figsize=(12, 15))\n",
    "for i, feature in enumerate(features):\n",
    "    sns.boxplot(x='MilkQuality', y=feature, data=df_sample, ax=axes[i])\n",
    "    axes[i].set_title(f'{feature} by Milk Quality', fontsize=12)\n",
    "    axes[i].set_xticklabels(axes[i].get_xticklabels(), rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f987e81",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing\n",
    "\n",
    "Prepare the data for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8dddbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features and target\n",
    "X = df[['pH', 'Turbidity', 'EC', 'Protein', 'SCC']]\n",
    "y = df['MilkQuality']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "print(\"Label Encoding Mapping:\")\n",
    "for i, label in enumerate(label_encoder.classes_):\n",
    "    print(f\"{label} -> {i}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb485141",
   "metadata": {},
   "source": [
    "## 4. Train/Test Split (80/20)\n",
    "\n",
    "Split the data for training and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defde060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets (80/20 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {X_train.shape[0]} samples ({X_train.shape[0]/len(X_scaled):.1%})\")\n",
    "print(f\"Testing set size: {X_test.shape[0]} samples ({X_test.shape[0]/len(X_scaled):.1%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db741f88",
   "metadata": {},
   "source": [
    "## 5. Model Training and Evaluation\n",
    "\n",
    "Train and evaluate multiple machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d692906",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models to evaluate\n",
    "models = {\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),\n",
    "    'SVM': SVC(kernel='rbf', probability=True, random_state=42)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "best_accuracy = 0\n",
    "best_model = None\n",
    "best_model_name = None\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    results[name] = accuracy\n",
    "    \n",
    "    print(f\"{name} Accuracy: {accuracy:.4f}\")\n",
    "    print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n",
    "    \n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_model = model\n",
    "        best_model_name = name\n",
    "\n",
    "print(f\"\\nBest Model: {best_model_name} (Accuracy: {best_accuracy:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d91d254",
   "metadata": {},
   "source": [
    "## 6. Model Analysis\n",
    "\n",
    "Analyze the best performing model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc8a1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate confusion matrix for the best model\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "\n",
    "conf_mat = confusion_matrix(y_test, y_pred_best)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(conf_mat, annot=True, fmt='d', \n",
    "            xticklabels=list(label_encoder.classes_), \n",
    "            yticklabels=list(label_encoder.classes_), \n",
    "            cmap='Blues')\n",
    "plt.title(f'Confusion Matrix - {best_model_name}', fontsize=14)\n",
    "plt.xlabel('Predicted', fontsize=12)\n",
    "plt.ylabel('Actual', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7527ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance analysis (if available)\n",
    "if hasattr(best_model, 'feature_importances_'):\n",
    "    importances = best_model.feature_importances_\n",
    "    features = ['pH', 'Turbidity', 'EC', 'Protein', 'SCC']\n",
    "    importance_df = pd.DataFrame({'Feature': features, 'Importance': importances})\n",
    "    importance_df = importance_df.sort_values('Importance', ascending=False)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x='Importance', y='Feature', data=importance_df)\n",
    "    plt.title('Feature Importance', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Feature Importance:\")\n",
    "    for index, row in importance_df.iterrows():\n",
    "        print(f\"{row['Feature']}: {row['Importance']:.4f}\")\n",
    "else:\n",
    "    print(f\"The {best_model_name} model does not provide feature importance information.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1028f1b",
   "metadata": {},
   "source": [
    "## 7. Model Comparison\n",
    "\n",
    "Compare the performance of all models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4bb0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot model accuracy comparison\n",
    "plt.figure(figsize=(12, 6))\n",
    "model_names = list(results.keys())\n",
    "accuracies = list(results.values())\n",
    "\n",
    "bars = plt.bar(model_names, accuracies, color=['#4361ee', '#3a0ca3', '#f72585', '#4cc9f0'])\n",
    "plt.title('Model Accuracy Comparison', fontsize=14)\n",
    "plt.xlabel('Model', fontsize=12)\n",
    "plt.ylabel('Accuracy', fontsize=12)\n",
    "plt.ylim(0, 1.0)  # Full scale to show realistic accuracy\n",
    "\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "             f'{height:.4f}', ha='center', va='bottom')\n",
    "\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365ba523",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation results\n",
    "cv_results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    cv_scores = cross_val_score(model, X_scaled, y_encoded, cv=5)\n",
    "    cv_results[name] = cv_scores\n",
    "    print(f\"{name} CV Accuracy: {cv_scores.mean():.4f} Â± {cv_scores.std():.4f}\")\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.boxplot([cv_results[name] for name in model_names], labels=model_names)\n",
    "plt.title('Cross-Validation Results', fontsize=14)\n",
    "plt.ylabel('Accuracy', fontsize=12)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642a6777",
   "metadata": {},
   "source": [
    "## 8. Model Saving\n",
    "\n",
    "Save the best model for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7aac1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create models directory if it doesn't exist\n",
    "os.makedirs('models', exist_ok=True)\n",
    "\n",
    "joblib.dump(best_model, 'models/milk_quality_model.pkl')\n",
    "joblib.dump(scaler, 'models/scaler.pkl')\n",
    "joblib.dump(label_encoder, 'models/label_encoder.pkl')\n",
    "\n",
    "print(f\"Best model ({best_model_name}) and preprocessing components saved successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9de357",
   "metadata": {},
   "source": [
    "## 9. Prediction Examples\n",
    "\n",
    "Demonstrate how to use the model for predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466b2831",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example milk readings\n",
    "example_readings = [\n",
    "    {'ph': 6.8, 'turbidity': 2.5, 'ec': 4.5, 'protein': 3.2, 'scc': 150000},  # Should be Negative/Healthy\n",
    "    {'ph': 6.3, 'turbidity': 6.0, 'ec': 5.2, 'protein': 2.9, 'scc': 350000},  # Should be Trace/Monitor\n",
    "    {'ph': 5.8, 'turbidity': 15.0, 'ec': 6.5, 'protein': 2.2, 'scc': 3000000}  # Should be Distinct_Positive/Problematic\n",
    "]\n",
    "\n",
    "action_mapping = {\n",
    "    'Negative': 'Safe to use',\n",
    "    'Trace': 'Monitor',\n",
    "    'Weak_Positive': 'Check the cow',\n",
    "    'Distinct_Positive': 'Veterinary care',\n",
    "    'Definite_Positive': 'Reject the milk'\n",
    "}\n",
    "\n",
    "print(\"Prediction Examples:\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for i, reading in enumerate(example_readings):\n",
    "    input_data = np.array([[reading['ph'], reading['turbidity'], reading['ec'], \n",
    "                           reading['protein'], reading['scc']]])\n",
    "    \n",
    "    input_data_scaled = scaler.transform(input_data)\n",
    "    \n",
    "    prediction = best_model.predict(input_data_scaled)[0]\n",
    "    quality_category = label_encoder.inverse_transform([prediction])[0]\n",
    "    \n",
    "    action = action_mapping.get(quality_category, 'Unknown')\n",
    "    \n",
    "    print(f\"Example {i+1}:\")\n",
    "    print(f\"Input: {reading}\")\n",
    "    print(f\"Predicted Quality: {quality_category}\")\n",
    "    print(f\"Recommended Action: {action}\")\n",
    "    print(\"-\" * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
