{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {},
  "cells": [
    {
      "id": "c6d41e58",
      "cell_type": "markdown",
      "source": "# Milk Quality Analysis and Machine Learning Pipeline\n\nThis notebook demonstrates the process of generating synthetic sensor data for milk quality analysis, performing exploratory data analysis (EDA), preprocessing, training multiple machine learning models, and evaluating their performance.",
      "metadata": {}
    },
    {
      "id": "1c03f32a",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "#!/usr/bin/env python\n\n#",
      "outputs": []
    },
    {
      "id": "29a7079b",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\nimport joblib\nimport os\n\nplt.style.use('seaborn-v0_8-whitegrid')\nsns.set_palette('viridis')",
      "outputs": []
    },
    {
      "id": "9e691531",
      "cell_type": "markdown",
      "source": "## 1. Data Generation\n\nGenerate synthetic milk quality data with various parameters.",
      "metadata": {}
    },
    {
      "id": "f3decc6f",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "def generate_training_data(n_samples=200000):\n    np.random.seed(42)\n    \n    ph_values = np.random.uniform(5.5, 7.5, n_samples)  # Expanded pH range\n    turbidity = np.random.uniform(0.5, 30.0, n_samples)  # Expanded turbidity range\n    ec_values = np.random.uniform(3.5, 7.0, n_samples)   # Expanded EC range\n    protein_content = np.random.uniform(1.5, 4.0, n_samples)  # Expanded protein range\n    \n    w1, w2, C = 1.2, 2.0, 1000\n    scc_values = (w1 * ec_values) + (w2 * turbidity) + C\n    scc_values += np.random.normal(0, 1000000, n_samples)  # larger noise for more variability\n    scc_values = np.clip(np.abs(scc_values), 1000, 10_000_000)  # clip to realistic limits\n    \n    action_mapping = {\n        'Negative': 'Safe to use',\n        'Trace': 'Monitor',\n        'Weak_Positive': 'Check the cow',\n        'Distinct_Positive': 'Veterinary care',\n        'Definite_Positive': 'Reject the milk'\n    }\n    \n    quality_categories = []\n    actions = []\n    for scc in scc_values:\n        if scc <= 200_000:\n            label = 'Negative'\n        elif scc <= 400_000:\n            label = 'Trace'\n        elif scc <= 1_200_000:\n            label = 'Weak_Positive'\n        elif scc <= 5_000_000:\n            label = 'Distinct_Positive'\n        else:\n            label = 'Definite_Positive'\n        quality_categories.append(label)\n        actions.append(action_mapping[label])\n    \n    return pd.DataFrame({\n        'pH': ph_values,\n        'Turbidity': turbidity,\n        'EC': ec_values,\n        'Protein': protein_content,\n        'SCC': scc_values,\n        'MilkQuality': quality_categories,\n        'Action': actions\n    })\n\ndf = generate_training_data()\ndf.head()",
      "outputs": []
    },
    {
      "id": "4ee955f4",
      "cell_type": "markdown",
      "source": "## 2. Data Distribution Analysis\n\nExamine the distribution of milk quality categories.",
      "metadata": {}
    },
    {
      "id": "b099a0fa",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "quality_counts = df['MilkQuality'].value_counts()\nprint(\"Milk Quality Distribution:\")\nprint(quality_counts)\nprint(\"\\nPercentage Distribution:\")\nprint(quality_counts / len(df) * 100)\n\nplt.figure(figsize=(12,6))\nsns.countplot(data=df, x='MilkQuality', order=df['MilkQuality'].value_counts().index, palette='viridis')\nplt.title('Milk Quality Distribution')\nplt.ylabel('Count')\nplt.xlabel('Quality Category')\nplt.xticks(rotation=45)\nplt.tight_layout()\nplt.show()",
      "outputs": []
    },
    {
      "id": "5512b1bc",
      "cell_type": "markdown",
      "source": "## 3. Exploratory Data Analysis\n\nVisualize relationships between features and milk quality.",
      "metadata": {}
    },
    {
      "id": "cdc9aa30",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "df_sample = df.sample(1000, random_state=42)\n\nsns.pairplot(df_sample, hue='MilkQuality', vars=['pH', 'Turbidity', 'EC', 'Protein', 'SCC'])\nplt.suptitle('Pairplot of Sampled Milk Data', y=1.02)\nplt.show()",
      "outputs": []
    },
    {
      "id": "e657390c",
      "cell_type": "markdown",
      "source": "## 4. Feature Analysis by Quality Category\n\nAnalyze how features vary across different milk quality categories.",
      "metadata": {}
    },
    {
      "id": "55a9ecce",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "features = ['pH', 'Turbidity', 'EC', 'Protein', 'SCC']\n\nfig, axes = plt.subplots(len(features), 1, figsize=(12, 15))\nfor i, feature in enumerate(features):\n    sns.boxplot(x='MilkQuality', y=feature, data=df_sample, ax=axes[i])\n    axes[i].set_title(f'{feature} by Milk Quality')\n    axes[i].set_xticklabels(axes[i].get_xticklabels(), rotation=45)\n\nplt.tight_layout()\nplt.show()",
      "outputs": []
    },
    {
      "id": "216ef133",
      "cell_type": "markdown",
      "source": "## 5. Data Preprocessing\n\nPrepare data for machine learning by scaling features and encoding labels.",
      "metadata": {}
    },
    {
      "id": "132cddcb",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "X = df[['pH', 'Turbidity', 'EC', 'Protein', 'SCC']]\ny = df['MilkQuality']\n\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\nlabel_encoder = LabelEncoder()\ny_encoded = label_encoder.fit_transform(y)\n\nprint(\"Label Encoding Mapping:\")\nfor i, label in enumerate(label_encoder.classes_):\n    print(f\"{label} -> {i}\")",
      "outputs": []
    },
    {
      "id": "89583974",
      "cell_type": "markdown",
      "source": "## 6. Train/Test Split\n\nSplit data into training (80%) and testing (20%) sets.",
      "metadata": {}
    },
    {
      "id": "43dfd2a5",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "X_train, X_test, y_train, y_test = train_test_split(\n    X_scaled, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded\n)\n\nprint(f\"Training set size: {X_train.shape[0]} samples\")\nprint(f\"Testing set size: {X_test.shape[0]} samples\")",
      "outputs": []
    },
    {
      "id": "2bb8257f",
      "cell_type": "markdown",
      "source": "## 7. Model Training and Evaluation\n\nTrain multiple machine learning models and compare their performance.",
      "metadata": {}
    },
    {
      "id": "76282d72",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "models = {\n    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n    'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, random_state=42),\n    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),\n    'SVM': SVC(kernel='rbf', probability=True, random_state=42)\n}\n\nresults = {}\nbest_accuracy = 0\nbest_model = None\nbest_model_name = None\n\nfor name, model in models.items():\n    print(f\"\\nTraining {name}...\")\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    accuracy = accuracy_score(y_test, y_pred)\n    results[name] = accuracy\n    \n    print(f\"{name} Accuracy: {accuracy:.4f}\")\n    print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n    \n    if accuracy > best_accuracy:\n        best_accuracy = accuracy\n        best_model = model\n        best_model_name = name\n\nprint(f\"\\nBest Model: {best_model_name} (Accuracy: {best_accuracy:.4f})\")",
      "outputs": []
    },
    {
      "id": "6c44f8c5",
      "cell_type": "markdown",
      "source": "## 8. Confusion Matrix\n\nVisualize the confusion matrix for the best performing model.",
      "metadata": {}
    },
    {
      "id": "ec103d13",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "y_pred_best = best_model.predict(X_test)\n\nconf_mat = confusion_matrix(y_test, y_pred_best)\n\nplt.figure(figsize=(10, 6))\nsns.heatmap(conf_mat, annot=True, fmt='d', \n            xticklabels=list(label_encoder.classes_), \n            yticklabels=list(label_encoder.classes_), \n            cmap='Blues')\nplt.title(f'Confusion Matrix - {best_model_name}')\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.tight_layout()\nplt.show()",
      "outputs": []
    },
    {
      "id": "425e5186",
      "cell_type": "markdown",
      "source": "## 4. Feature Analysis by Quality Category\n\nAnalyze how features vary across different milk quality categories.",
      "metadata": {}
    },
    {
      "id": "b24ffcdb",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "if hasattr(best_model, 'feature_importances_'):\n    importances = best_model.feature_importances_\n    features = ['pH', 'Turbidity', 'EC', 'Protein', 'SCC']\n    importance_df = pd.DataFrame({'Feature': features, 'Importance': importances})\n    importance_df = importance_df.sort_values('Importance', ascending=False)\n    \n    plt.figure(figsize=(10, 6))\n    sns.barplot(x='Importance', y='Feature', data=importance_df)\n    plt.title('Feature Importance')\n    plt.tight_layout()\n    plt.show()\n    \n    print(\"Feature Importance:\")\n    for index, row in importance_df.iterrows():\n        print(f\"{row['Feature']}: {row['Importance']:.4f}\")\nelse:\n    print(f\"The {best_model_name} model does not provide feature importance information.\")",
      "outputs": []
    },
    {
      "id": "c67b0c10",
      "cell_type": "markdown",
      "source": "## 10. Model Comparison\n\nCompare the accuracy of different machine learning models.",
      "metadata": {}
    },
    {
      "id": "e005aaa0",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "plt.figure(figsize=(10, 6))\nmodel_names = list(results.keys())\naccuracies = list(results.values())\n\nbars = plt.bar(model_names, accuracies, color='skyblue')\nplt.title('Model Accuracy Comparison')\nplt.xlabel('Model')\nplt.ylabel('Accuracy')\nplt.ylim(0.9, 1.0)  # Adjust as needed based on your results\n\nfor bar in bars:\n    height = bar.get_height()\n    plt.text(bar.get_x() + bar.get_width()/2., height + 0.001,\n             f'{height:.4f}', ha='center', va='bottom')\n\nplt.tight_layout()\nplt.show()",
      "outputs": []
    },
    {
      "id": "906b6bf6",
      "cell_type": "markdown",
      "source": "## 11. Cross-Validation\n\nPerform cross-validation to ensure model robustness.",
      "metadata": {}
    },
    {
      "id": "4743be8e",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "from sklearn.model_selection import cross_val_score\n\ncv_results = {}\n\nfor name, model in models.items():\n    cv_scores = cross_val_score(model, X_scaled, y_encoded, cv=5)\n    cv_results[name] = cv_scores\n    print(f\"{name} CV Accuracy: {cv_scores.mean():.4f} \u00b1 {cv_scores.std():.4f}\")\n\nplt.figure(figsize=(10, 6))\nplt.boxplot([cv_results[name] for name in model_names], labels=model_names)\nplt.title('Cross-Validation Results')\nplt.ylabel('Accuracy')\nplt.grid(axis='y', linestyle='--', alpha=0.7)\nplt.tight_layout()\nplt.show()",
      "outputs": []
    },
    {
      "id": "e8eb7b70",
      "cell_type": "markdown",
      "source": "## 12. Model Saving\n\nSave the best model and preprocessing components for deployment.",
      "metadata": {}
    },
    {
      "id": "1e58294b",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "os.makedirs('models', exist_ok=True)\n\njoblib.dump(best_model, 'models/milk_quality_model.pkl')\njoblib.dump(scaler, 'models/scaler.pkl')\njoblib.dump(label_encoder, 'models/label_encoder.pkl')\n\nprint(f\"Best model ({best_model_name}) and preprocessing components saved successfully.\")",
      "outputs": []
    },
    {
      "id": "a146015c",
      "cell_type": "markdown",
      "source": "## 13. Prediction Examples\n\nTest the model with example milk quality readings.",
      "metadata": {}
    },
    {
      "id": "ded2db34",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "example_readings = [\n    {'ph': 6.8, 'turbidity': 2.5, 'ec': 4.5, 'protein': 3.2, 'scc': 150000},\n    {'ph': 6.3, 'turbidity': 6.0, 'ec': 5.2, 'protein': 2.9, 'scc': 350000},\n    {'ph': 5.8, 'turbidity': 15.0, 'ec': 6.5, 'protein': 2.2, 'scc': 3000000}\n]\n\naction_mapping = {\n    'Negative': 'Safe to use',\n    'Trace': 'Monitor',\n    'Weak_Positive': 'Check the cow',\n    'Distinct_Positive': 'Veterinary care',\n    'Definite_Positive': 'Reject the milk'\n}\n\nprint(\"Prediction Examples:\")\nprint(\"-\" * 80)\n\nfor i, reading in enumerate(example_readings):\n    input_data = np.array([[reading['ph'], reading['turbidity'], reading['ec'], \n                           reading['protein'], reading['scc']]])\n    \n    input_data_scaled = scaler.transform(input_data)\n    \n    prediction = best_model.predict(input_data_scaled)[0]\n    quality_category = label_encoder.inverse_transform([prediction])[0]\n    \n    action = action_mapping.get(quality_category, 'Unknown')\n    \n    print(f\"Example {i+1}:\")\n    print(f\"Input: {reading}\")\n    print(f\"Predicted Quality: {quality_category}\")\n    print(f\"Recommended Action: {action}\")\n    print(\"-\" * 80)",
      "outputs": []
    }
  ]
}