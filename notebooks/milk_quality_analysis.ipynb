{"nbformat": 4, "nbformat_minor": 5, "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.8.10"}}, "cells": [{"id": "7b175640", "cell_type": "markdown", "source": "#!/usr/bin/env python\n\n# \n\n\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\nimport joblib\nimport os\n\nplt.style.use('seaborn-v0_8-whitegrid')\nsns.set_palette('viridis')\n\n\n\n\n\ndef generate_training_data(n_samples=200000):\n    np.random.seed(42)\n    \n    ph_values = np.random.uniform(5.5, 7.5, n_samples)  # Expanded pH range\n    turbidity = np.random.uniform(0.5, 30.0, n_samples)  # Expanded turbidity range\n    ec_values = np.random.uniform(3.5, 7.0, n_samples)   # Expanded EC range\n    protein_content = np.random.uniform(1.5, 4.0, n_samples)  # Expanded protein range\n    \n    scc_distribution = np.random.choice(['low', 'medium', 'high', 'very_high', 'extreme'], \n                                      size=n_samples, \n                                      p=[0.4, 0.3, 0.15, 0.1, 0.05])  # Adjusted probabilities\n    \n    scc_values = np.zeros(n_samples)\n    for i, dist in enumerate(scc_distribution):\n        if dist == 'low':\n            scc_values[i] = np.random.uniform(10000, 200000)\n        elif dist == 'medium':\n            scc_values[i] = np.random.uniform(200001, 400000)\n        elif dist == 'high':\n            scc_values[i] = np.random.uniform(400001, 1200000)\n        elif dist == 'very_high':\n            scc_values[i] = np.random.uniform(1200001, 5000000)\n        else:  # extreme\n            scc_values[i] = np.random.uniform(5000001, 10000000)\n    \n    action_mapping = {\n        'Negative': 'Safe to use',\n        'Trace': 'Monitor',\n        'Weak_Positive': 'Check the cow',\n        'Distinct_Positive': 'Veterinary care',\n        'Definite_Positive': 'Reject the milk'\n    }\n    \n    quality_categories = []\n    actions = []\n    for scc in scc_values:\n        if scc <= 200_000:\n            label = 'Negative'\n        elif scc <= 400_000:\n            label = 'Trace'\n        elif scc <= 1_200_000:\n            label = 'Weak_Positive'\n        elif scc <= 5_000_000:\n            label = 'Distinct_Positive'\n        else:\n            label = 'Definite_Positive'\n        quality_categories.append(label)\n        actions.append(action_mapping[label])\n    \n    return pd.DataFrame({\n        'pH': ph_values,\n        'Turbidity': turbidity,\n        'EC': ec_values,\n        'Protein': protein_content,\n        'SCC': scc_values,\n        'MilkQuality': quality_categories,\n        'Action': actions\n    })\n\ndf = generate_training_data()\ndf.head()\n\n\n\n\n\nquality_counts = df['MilkQuality'].value_counts()\nprint(\"Milk Quality Distribution:\")\nprint(quality_counts)\nprint(\"\\nPercentage Distribution:\")\nprint(quality_counts / len(df) * 100)\n\nplt.figure(figsize=(12,6))\nsns.countplot(data=df, x='MilkQuality', order=df['MilkQuality'].value_counts().index, palette='viridis')\nplt.title('Milk Quality Distribution')\nplt.ylabel('Count')\nplt.xlabel('Quality Category')\nplt.xticks(rotation=45)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\ndf_sample = df.sample(1000, random_state=42)\n\nsns.pairplot(df_sample, hue='MilkQuality', vars=['pH', 'Turbidity', 'EC', 'Protein', 'SCC'])\nplt.suptitle('Pairplot of Sampled Milk Data', y=1.02)\nplt.show()\n\n\n\n\nfeatures = ['pH', 'Turbidity', 'EC', 'Protein', 'SCC']\n\nfig, axes = plt.subplots(len(features), 1, figsize=(12, 15))\nfor i, feature in enumerate(features):\n    sns.boxplot(x='MilkQuality', y=feature, data=df_sample, ax=axes[i])\n    axes[i].set_title(f'{feature} by Milk Quality')\n    axes[i].set_xticklabels(axes[i].get_xticklabels(), rotation=45)\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\nX = df[['pH', 'Turbidity', 'EC', 'Protein', 'SCC']]\ny = df['MilkQuality']\n\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\nlabel_encoder = LabelEncoder()\ny_encoded = label_encoder.fit_transform(y)\n\nprint(\"Label Encoding Mapping:\")\nfor i, label in enumerate(label_encoder.classes_):\n    print(f\"{label} -> {i}\")\n\n\n\n\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X_scaled, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded\n)\n\nprint(f\"Training set size: {X_train.shape[0]} samples\")\nprint(f\"Testing set size: {X_test.shape[0]} samples\")\n\n\n\n\n\nmodels = {\n    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n    'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, random_state=42),\n    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),\n    'SVM': SVC(kernel='rbf', probability=True, random_state=42)\n}\n\nresults = {}\nbest_accuracy = 0\nbest_model = None\nbest_model_name = None\n\nfor name, model in models.items():\n    print(f\"\\nTraining {name}...\")\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    accuracy = accuracy_score(y_test, y_pred)\n    results[name] = accuracy\n    \n    print(f\"{name} Accuracy: {accuracy:.4f}\")\n    print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n    \n    if accuracy > best_accuracy:\n        best_accuracy = accuracy\n        best_model = model\n        best_model_name = name\n\nprint(f\"\\nBest Model: {best_model_name} (Accuracy: {best_accuracy:.4f})\")\n\n\n\n\n\ny_pred_best = best_model.predict(X_test)\n\nconf_mat = confusion_matrix(y_test, y_pred_best)\n\nplt.figure(figsize=(10, 6))\nsns.heatmap(conf_mat, annot=True, fmt='d', \n            xticklabels=list(label_encoder.classes_), \n            yticklabels=list(label_encoder.classes_), \n            cmap='Blues')\nplt.title(f'Confusion Matrix - {best_model_name}')\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.tight_layout()\nplt.show()\n\n\n\n\n\nif hasattr(best_model, 'feature_importances_'):\n    importances = best_model.feature_importances_\n    features = ['pH', 'Turbidity', 'EC', 'Protein', 'SCC']\n    importance_df = pd.DataFrame({'Feature': features, 'Importance': importances})\n    importance_df = importance_df.sort_values('Importance', ascending=False)\n    \n    plt.figure(figsize=(10, 6))\n    sns.barplot(x='Importance', y='Feature', data=importance_df)\n    plt.title('Feature Importance')\n    plt.tight_layout()\n    plt.show()\n    \n    print(\"Feature Importance:\")\n    for index, row in importance_df.iterrows():\n        print(f\"{row['Feature']}: {row['Importance']:.4f}\")\nelse:\n    print(f\"The {best_model_name} model does not provide feature importance information.\")\n\n\n\n\n\nplt.figure(figsize=(10, 6))\nmodel_names = list(results.keys())\naccuracies = list(results.values())\n\nbars = plt.bar(model_names, accuracies, color='skyblue')\nplt.title('Model Accuracy Comparison')\nplt.xlabel('Model')\nplt.ylabel('Accuracy')\nplt.ylim(0.9, 1.0)  # Adjust as needed based on your results\n\nfor bar in bars:\n    height = bar.get_height()\n    plt.text(bar.get_x() + bar.get_width()/2., height + 0.001,\n             f'{height:.4f}', ha='center', va='bottom')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\nfrom sklearn.model_selection import cross_val_score\n\ncv_results = {}\n\nfor name, model in models.items():\n    cv_scores = cross_val_score(model, X_scaled, y_encoded, cv=5)\n    cv_results[name] = cv_scores\n    print(f\"{name} CV Accuracy: {cv_scores.mean():.4f} \u00b1 {cv_scores.std():.4f}\")\n\nplt.figure(figsize=(10, 6))\nplt.boxplot([cv_results[name] for name in model_names], labels=model_names)\nplt.title('Cross-Validation Results')\nplt.ylabel('Accuracy')\nplt.grid(axis='y', linestyle='--', alpha=0.7)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\nos.makedirs('models', exist_ok=True)\n\njoblib.dump(best_model, 'models/milk_quality_model.pkl')\njoblib.dump(scaler, 'models/scaler.pkl')\njoblib.dump(label_encoder, 'models/label_encoder.pkl')\n\nprint(f\"Best model ({best_model_name}) and preprocessing components saved successfully.\")\n\n\n\n\n\nexample_readings = [\n    {'ph': 6.8, 'turbidity': 2.5, 'ec': 4.5, 'protein': 3.2, 'scc': 150000},\n    {'ph': 6.3, 'turbidity': 6.0, 'ec': 5.2, 'protein': 2.9, 'scc': 350000},\n    {'ph': 5.8, 'turbidity': 15.0, 'ec': 6.5, 'protein': 2.2, 'scc': 3000000}\n]\n\naction_mapping = {\n    'Negative': 'Safe to use',\n    'Trace': 'Monitor',\n    'Weak_Positive': 'Check the cow',\n    'Distinct_Positive': 'Veterinary care',\n    'Definite_Positive': 'Reject the milk'\n}\n\nprint(\"Prediction Examples:\")\nprint(\"-\" * 80)\n\nfor i, reading in enumerate(example_readings):\n    input_data = np.array([[reading['ph'], reading['turbidity'], reading['ec'], \n                           reading['protein'], reading['scc']]])\n    \n    input_data_scaled = scaler.transform(input_data)\n    \n    prediction = best_model.predict(input_data_scaled)[0]\n    quality_category = label_encoder.inverse_transform([prediction])[0]\n    \n    action = action_mapping.get(quality_category, 'Unknown')\n    \n    print(f\"Example {i+1}:\")\n    print(f\"Input: {reading}\")\n    print(f\"Predicted Quality: {quality_category}\")\n    print(f\"Recommended Action: {action}\")\n    print(\"-\" * 80)", "metadata": {}}]}